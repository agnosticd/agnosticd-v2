= Conversion Guide

In AgnosticD V2 a lot of code has been cleaned up, streamlined and in general made more logical. Therefore it is necessary to keep a few things in mind when deploying an AgnosticV config from AgnosticD V1 to the new AgnosticD V2.

This is supposed to be a comprehensive list - but in case some variables have been missed this guide will be updated.

== Common changes

* `env_type` is now called `config`.
* `ec2` cloud provider has been renamed to `aws` for consistency.
* At the moment `aws` and `none` are the only supported (working) cloud providers. As more cloud providers are converted/updated/modernized this document will be updated.
* Because cloud providers are now in a separate collection and not part of the core repository it is now possible to lock a version for the collection by specifying a branch or tag via the variable `cloud_provider_version`. If no `cloud_provider_version` is specified the default `main`is used.
** Cloud Provider playbooks remain in AgdV2. But they have been moved to the `cloud_provider/{{ cloud_provider }}` directory. Valid playbooks are `infrastructure_deployment.yml`, `destroy_env.yml` and `lifecycle.yml`. All roles have been/should be refactored into a collection like the `aws` cloud provider.
* All `AgnosticD` plugins have been consolidated into a collection. This collection is embedded into the AgnosticD V2 repository (`/ansible/collections/ansible_collections/agnosticd/core`). Therefore it is necessary to use the fully qualified plugin name in AgnosticD (or workload) code. Note that lookup plugins are also symlinked into `/ansible/lookup_plugins` for Babylon compability (Babylon sets variables from Vault using `unvault_string` and changing Babylon would break old deployments).
** `agnosticd.core.agnosticd_user_info` (Action plugin/Module)
** `agnosticd.core.agnosticd_odcr` (Action plugin)
** `agnosticd.core.agnosticd_user_data` (Lookup plugin)
** `agnosticd.core.bitwarden` (Lookup plugin)
** `agnosticd.core.unvault_string` (Lookup plugins.)
* `software_to_deploy` does no longer exist. It was only used by OpenShift anyway. It has been replaced by `host_ocp4_deploy_installation_method` for the `openshift-cluster` config.
* Roles directory have been consolidated. `roles_infra`, `roles_studenvm` and `roles_ocp_workloads` no longer exist.
* Collections and roles are now installed *before* the `ansible/main.yml` playbook is executed. It is necessary to use a new Execution Environment image for this mechanism to work. At time of writing the full execution environment image is `quay.io/agnosticd/ee-multicloud:chained-2025-06-24` (note the `chained` prefix before the build date).
* There is no Python `virtualenv` installed on the bastion host anymore. The entire deployer runs in the execution environment container. If you *have* to run things on the bastion the tasks will to be pinned to the bastion using `delegate_to: "{{ groups['bastions'][0] }}"`
** All k8s tasks should be able to run from within the execution environment.

== OpenShift Cluster changes

The `ocp4-cluster` config has been renamed to `openshift-cluster`.
The term `master` has been replaced by `control_plane` where possible.
`infra_workloads` has been renamed to `workloads` and workloads now require the fully qualified role name
`student_workloads` have been removed

== DNS changes

TBD

== Common Role changes

=== Packages

install_common_packages: true

# To install extra packages (beyond what's in the common list of packages)
# host_common_packages_extramon_extra_packages:
# - java-17-openjdk
# - maven
# - podman

# Run a full dnf update on the hosts
host_common_packages_update_all: true

=== Satellite Repositories

install_satellite_repositories: true

# These vars are needed and need to come from secrets:
# host_satellite_repositories_hostname:
# host_satellite_repositories_ha:
# host_satellite_repositories_org:
# host_satellite_repositories_activationkey:

=== Bastion

install_bastion: true
bastion_student_user_name: lab-user
bastion_install_ftl: false

== Example: Convert OpenShift Cluster (Workshop) config from V1 to V2

* Create a new directory in AgnosticV - the `agd_v2` directory already exists and the `account.yml` file already has a few default variable mappings that enable the config to be deployed via the current Babylon mechanism.
* Copy `common.yaml` / `dev.yaml` / `description.adoc`
* Babylon `__meta__` changes:
** Generate a new asset_uuid
** Change the execution_environment image `image: quay.io/agnosticd/ee-multicloud:chained-2025-06-24`
** Change Display Name to something unique (add AgdV2 for example)
** Change Source Reference:
+
[source]
----
  deployer:
    scm_url: https://github.com/rhpds/agnosticd_v2
    scm_ref: main
----

* Mandatory variables changes:
** Change `env_type: ocp4-cluster` -> `config: openshift-cluster`
** Change `cloud_provider: ec2` -> `cloud_provider: aws`
** Add `cloud_provider_version: main`
** Remove software_to_deploy

* Add required collections. At a minimum:
+
[source,yaml]
----
# ===================================================================
# Additional Collections & roles to be installed for this config
# ===================================================================
requirements_content:
  collections:
  # Core OpenShift Workloads
  - name: https://github.com/agnosticd/core_workloads.git
    type: git
    version: main
----

* Change Bastion variables:
** `install_student_user` -> `bastion_setup_student_user`
** `student_name` -> `bastion_student_user_name`
** `student_sudo` -> `bastion_student_user_sudo`
** Other bastion student user variables that are available:
*** bastion_student_user_password: ""
*** bastion_student_user_password_length: 12 # Password length in case it's being generated
*** bastion_student_user_key: "" # Optional public key of the student user to be added to authorized_keys
*** bastion_student_user_set_user_data: true # Set agnosticd_user_info data with bastion access
*** bastion_student_user_show_user_info: true # Set agnosticd_user_info msg with bastion access

* Change node variables (master -> control_plane) if defined:
** `master_instance_count` -> `control_plane_instance_count`
** `master_instance_type_family` -> `control_plane_instance_type_family`
** `master_instance_type_size` -> `control_plane_instance_type_size`
** `master_instance_type` -> `control_plane_instance_type`
** `master_storage_type` -> `control_plane_storage_type`

* Workloads:
* Change list of `infra_workloads` to `workloads` and to use fully qualified collection name for the workload role (and change authentication workload name):
+
.Old
[source,yaml]
----
infra_workloads:
- ocp4_workload_authentication
- ocp4_workload_cert_manager
----
+
.New
[source,yaml]
----
workloads:
- agnosticd.core_workloads.ocp4_workload_authentication_htpasswd
- agnosticd.core_workloads.ocp4_workload_cert_manager
----

* Workload specific changes
** `ocp4_workload_authentication` has been renamed to `ocp4_workload_authentication_htpasswd` because it only sets up htpasswd at this point (LDAP has not been supported/used in years)
*** Delete `ocp4_workload_authentication_idm_type: htpasswd`
*** Change `ocp4_workload_authentication_remove_kubeadmin: true` -> `ocp4_workload_authentication_htpasswd_remove_kubeadmin: true`
*** Change `ocp4_workload_authentication_admin_user: admin` -> `ocp4_workload_authentication_htpasswd_admin_user: admin`

